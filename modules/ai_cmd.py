import os
import requests

from dotenv import load_dotenv
from pathlib import Path
from utils.check_text_type import is_url, is_vietnamese
from utils.long_message import send_long_message

ALLOWED_USER_IDS = [377676460334514176]

# --- Setup bot ---
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

# --- File path ---
__File__ = Path(__file__).parent.resolve()
project_dir = __File__.parent

# --- !summarize: summarize url or long text ---
async def summarize(ctx, *, message_text: str):

    # Text to chat
    await ctx.channel.send(f"üîçüìù Summarizing...")

    # Check if message_text url or text
    if is_url(message_text):

        # prompt for AI
        base_prompt = "Summarize the main information from the webpage at this URL. Provide a brief and clear summary of the key ideas and important details: "
        # Combine prompt and msg
        messages = [{
            "role": "system",
            "content": base_prompt + ctx.content
        }]

        # AI url
        url = "https://api.groq.com/openai/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }
        data = {
            "model": "llama-3.3-70b-versatile",
            "messages": messages
        }

        # try to take response from AI model
        try:
            response = requests.post(url, headers=headers, json=data)
            data = response.json()["choices"][0]["message"]["content"]
            await send_long_message(ctx.channel, data) or "‚ùå No response from Herta."
        except requests.exceptions.RequestException:
            await ctx.channel.send("‚ö†Ô∏è Failed to connect to Herta API.")
    else:
        # prompt for AI
        base_prompt = "Summarize the following passage into key points as bullet points, each point concise and easy to understand:"

        # Combine prompt and msg
        messages = [{
            "role": "system",
            "content": base_prompt + ctx.content
        }]

        # AI url
        url = "https://api.groq.com/openai/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }
        data = {
            "model": "llama-3.3-70b-versatile",
            "messages": messages
        }

        # try to take response from AI model
        try:
            response = requests.post(url, headers=headers, json=data)
            data = response.json()["choices"][0]["message"]["content"]
            await send_long_message(ctx.channel, data) or "‚ùå No response from Herta."
        except requests.exceptions.RequestException:
            await ctx.channel.send("‚ö†Ô∏è Failed to connect to Herta API.")

# --- !translate: vi <-> en ---
async def translate(ctx, *, message_text: str):
    # Text to chat
    await ctx.channel.send(f"üáªüá≥üîÅüá¨üáß Translating...")

    # Check if message_text is vi or en
    if is_vietnamese(message_text):
        # prompt for AI
        base_prompt = f"Translate the following Vietnamese text into English: "

        # Combine prompt and msg
        messages = [{
            "role": "system",
            "content": base_prompt + ctx.content
        }]
        # AI url
        url = "https://api.groq.com/openai/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }
        data = {
            "model": "llama-3.3-70b-versatile",
            "messages": messages
        }

        # try to take response from AI model
        try:
            response = requests.post(url, headers=headers, json=data)
            data = response.json()["choices"][0]["message"]["content"]
            await send_long_message(ctx.channel, data) or "‚ùå No response from Herta."
        except requests.exceptions.RequestException:
            await ctx.channel.send("‚ö†Ô∏è Failed to connect to Herta API.")
    else:
        # prompt for AI
        base_prompt = f"D·ªãch ƒëo·∫°n vƒÉn ti·∫øng Anh sau sang ti·∫øng Vi·ªát: "

        # Combine prompt and msg
        messages = [{
            "role": "system",
            "content": base_prompt + ctx.content
        }]
        # AI url
        url = "https://api.groq.com/openai/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json"
        }
        data = {
            "model": "llama-3.3-70b-versatile",
            "messages": messages
        }

        # try to take response from AI model
        try:
            response = requests.post(url, headers=headers, json=data)
            data = response.json()["choices"][0]["message"]["content"]
            await send_long_message(ctx.channel, data) or "‚ùå No response from Herta."
        except requests.exceptions.RequestException:
            await ctx.channel.send("‚ö†Ô∏è Failed to connect to Herta API.")

# --- !fix_grammar: fix grammar ---
async def fix_grammar(ctx):
    # Text to chat
    await ctx.channel.send(f"üìùüîß Fixing grammar...")

    # prompt for AI
    base_prompt = f"Fix the grammar and spelling errors in this text: "

    # Combine prompt and msg
    messages = [{
        "role": "system",
        "content": base_prompt + ctx.content
    }]
    # AI url
    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }
    data = {
        "model": "llama-3.3-70b-versatile",
        "messages": messages
    }

    # try to take response from AI model
    try:
        response = requests.post(url, headers=headers, json=data)
        data = response.json()["choices"][0]["message"]["content"]
        await send_long_message(ctx.channel, data) or "‚ùå No response from Herta."
    except requests.exceptions.RequestException:
        await ctx.channel.send("‚ö†Ô∏è Failed to connect to Herta API.")